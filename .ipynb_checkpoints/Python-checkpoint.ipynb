{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6b7f6b-675d-4191-af6c-2fa68dde6559",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54539251-5f6e-42df-98ec-08daa88a1435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from stopwords import get_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce2488-0bd1-4011-8140-0314cca3a4de",
   "metadata": {},
   "source": [
    "Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bcce439-9cbc-40a9-a99e-a6177517ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = pd.read_csv(\"speeches.csv\", sep=\"|\")\n",
    "speeches.columns = speeches.columns.str.lower()\n",
    "speeches = speeches[[\"date\", \"contents\"]]\n",
    "\n",
    "fx = pd.read_csv(\"fx.csv\")\n",
    "fx.columns = fx.columns.str.lower()\n",
    "fx.rename(columns={fx.columns[2]: \"rate\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44caaf7-4581-44ee-b0aa-f66630def623",
   "metadata": {},
   "source": [
    "Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b834c501-8ddc-4457-bef2-c6cc3716a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fx.merge(speeches, how=\"left\", on=\"date\")\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"], errors=\"coerce\")\n",
    "\n",
    "data = data.sort_values(\"date\")\n",
    "data[\"rate\"] = data[\"rate\"].ffill()\n",
    "data = data.dropna(subset=[\"rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb0e875-ee9a-47c3-8622-e9ff6b4228d4",
   "metadata": {},
   "source": [
    "Exchange rate return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf7d975-69fc-4f32-a03a-5b1036c56494",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"return\"] = 100 * (data[\"rate\"] / data[\"rate\"].shift(1) - 1)\n",
    "data[\"good_news\"] = (data[\"return\"] > 0.5).astype(int)\n",
    "data[\"bad_news\"] = (data[\"return\"] < -0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd9347c-ec74-4f28-b972-1f95b8643201",
   "metadata": {},
   "source": [
    "Find words and remove artciles..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42021134-ef93-4670-afb8-f335bbc20cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=[\"contents\"])\n",
    "\n",
    "#stopwords\n",
    "stop_en = get_stopwords(\"en\")\n",
    "stop_pt = get_stopwords(\"pt\")\n",
    "stop_es = get_stopwords(\"es\")\n",
    "stop_fr = get_stopwords(\"fr\")\n",
    "stop_de = get_stopwords(\"de\")\n",
    "stop_words = set(stop_en + stop_pt + stop_es + stop_fr + stop_de)\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}\\\\d]\", \" \", text)\n",
    "    words = text.split()\n",
    "    return [word for word in words if word not in stop_words and len(word) > 1]\n",
    "\n",
    "rows = []\n",
    "for _, row in data[[\"contents\", \"good_news\", \"bad_news\"]].iterrows():\n",
    "    tokens = tokenize(row[\"contents\"])\n",
    "    for word in tokens:\n",
    "        rows.append({\"word\": word, \"good_news\": row[\"good_news\"], \"bad_news\": row[\"bad_news\"]})\n",
    "\n",
    "data_words = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00334fc9-74be-4c2a-8ce1-0c342aa17f43",
   "metadata": {},
   "source": [
    "Good indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41229c01-84fc-4f38-a5fc-fa2dddfca5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_indicators = (\n",
    "    data_words[data_words[\"good_news\"] == 1]\n",
    "    .groupby(\"word\").size()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    "    .reset_index(name=\"n\")\n",
    ")\n",
    "good_indicators.to_csv(\"good_indicators.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe4634-b2d1-4c02-b204-79eed7d34531",
   "metadata": {},
   "source": [
    "Bad Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a799119-a042-41ad-8dd9-246f7cdb8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_indicators = (\n",
    "    data_words[data_words[\"bad_news\"] == 1]\n",
    "    .groupby(\"word\").size()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    "    .reset_index(name=\"n\")\n",
    ")\n",
    "bad_indicators.to_csv(\"bad_indicators.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
